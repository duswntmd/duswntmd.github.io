---
layout: single
title:  "로컬 딥시크"
toc: true
toc_sticky: true # 주석하면 고정
toc_label: 로컬 딥시크 # 오른쪽 목차 이름 변경가능
author_profile: true # true false로 왼쪽 삭제가능능
search: true # 검색기능에 나오게 할건지 여부       
---

## 로컬 llm 영상



## 올라마 설치

올라마 OS맞춰서 설치

[올라마 다운로드](https://ollama.com)

## 딥시크 다운로드

올라마 검색창 deepseek-r1 검색하고 사용 가능한 모델 다운로드  
cmd에서 실행!!
```
ollama
```
설치가 잘되었는지 확인  
전부 다운로드 했다면 대화창이 나옵니다.  
간단한 대화 확인하기  

```
/bye
```
채팅창 나오기

```
ollama list
```
올라마 다운 목록 확인하기

```
ollama run <모델명>
```
올라마 모델 다시 실행

```
ollama rm <모델명>
```
올라마 모델 삭제  

## open-webui 설치

채팅을 편하게 볼 UI 사용

[open-webui](https://github.com/open-webui/open-webui?tab=readme-ov-file)

2가지 방법이 있습니다.  
1. 컴퓨터에 깔아서 사용
2. 도커 이미지를 다운로드해서 사용

### 파이썬 설치

open-webui 사용하기 위해서 3.11이상 파이썬버전 필요

[python 다운로드](https://www.python.org/downloads/windows)

[![python 다운로드]({{site.url}}/images/2025-05-03-local-llm/파이썬다운로드.png)]({{site.url}}/images/2025-05-03-local-llm/파이썬다운로드.png)

```
python --version 
```

python 버전 확인

### 1. 컴퓨터에 깔아서 사용

```
pip install open-webui
```

```
open-webui serve
```

### 2. 도커 이미지를 다운로드해서 사용

docker-desktop 다운로드

[docker-desktop 다운로드](https://www.docker.com/products/docker-desktop)

도커회원가입후 로그인필요

```
docker --version
```

docker 버전 확인

```
docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main //cpu
```
cpu 사용
```
docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda //gpu
```
gpu 사용용

```
docker ps 
```

이미지 돌고있나 확인  
주소창에 http://localhost:3000 들어가기

관리자 계정 생성 (아무거나 하시면 됩니다)

[![open webui관리자계정사진]({{site.url}}/images/2025-05-03-local-llm/open webui관리자계정사진.png)]({{site.url}}/images/2025-05-03-local-llm/open webui관리자계정사진.png)

```
docker stop <컨테이너 아이디>
```

이미지 종료

```
docker start <컨테이너 아이디>
```

이미지 시작